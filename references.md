---
layout: page
title: "References"
---

[1a] R´emi Delbouys, Romain Hennequin, Francesco Piccoli, Jimena Royo-Letelier, Manuel Moussallam. Music Mood Detection Based on Audio and Lyrics with Deep Neural Net. 2018.

[2a] Xiao Hu, J. Stephen Downie, and Andreas F. Ehmann. LYRIC TEXT MINING IN MUSIC MOOD CLASSIFICATION. 2009.

[3a] Cyril Laurier, Jens Grivolla, and Perfecto Herrera. Multimodal Music Mood Classification using Audio and Lyrics. 2008.

[4a] Erion Cano and Maurizio Morisio. MoodyLyrics: A Sentiment Annotated Lyrics Dataset. 2017.

[5a] Ricardo Malheiro, Renato Panda, Paulo Gomes and Rui Pedro Paiva. Emotionally-Relevant Features for Classification and Regression of Music Lyrics. 2018.

[1x] Fernando Moya Rueda , René Grzeszick, Gernot A. Fink, Sascha Feldhorst, and Michael ten Hompel. Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors. 2018.

[2x] Jian Bo Yang, Minh Nhut Nguyen, Phyo Phyo San, Xiao Li Li, and Shonali Krishnaswamy. Deep Convolutional Neural Networks On Multichannel Time Series For Human Activity Recognition. 2015.

[3x] Charissa Ann Ronao and Sung-Bae Cho. Deep Convolutional Neural Networks for Human Activity Recognition with Smartphone Sensors. 2015.

[4x] Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, and Lisha Hu. Deep Learning for Sensor-based Activity Recognition: A Survey. 2017.

[5x] Jennifer R. Kwapisz, Gary M. Weiss, and Samuel A. Moore. Activity Recognition using Cell Phone Accelerometers. 2010.

[6x] Abdulmajid Murad and Jae-Young Pyun. Deep Recurrent Neural Networks for Human Activity Recognition. 2017.

[1y] Mikhail Rumiantcev. MUSIC ADVISER – EMOTION-DRIVEN MUSIC RECOMMENDATION ECOSYSTEM. 2017.

[2y] Ivana Andjelkovica, Denis Parrab, and John O’Donovana. Moodplay: Interactive Music Recommendation based on Artists’ Mood Similarity. 2018.

[3] Delbouys et. al. Deezer mood detection dataset. https://github.com/deezer/deezer_mood_detection_dataset accessed February 2019.

[5] Kwapisz et. al. Activity prediction dataset. http://www.cis.fordham.edu/wisdm/dataset.php accessed February 2019. 

[7] Example: Sequence classification with 1D convolutions. https://keras.io/getting-started/sequential-model-guide/ accessed February 2019. 

[8] Netron. https://github.com/lutzroeder/netron accessed February 2019.

[10] Synchronized personalized music audio-playlists to improve adherence to physical activity among patients participating in a structured exercise program: a proof-of-principle feasibility study. Sports Med Open. 2015

[11] Promoting patient uptake and adherence in cardiac rehabilitation. Cochrane Database Syst Rev. 2010

[12] Hui-Min Wang and Sheng-Chieh Huang. Musical Rhythms Affect Heart Rate Variability: Algorithm and Models. 2014.

[13] J. A. Russell, “A circumplex model of affect,” Journal of Personality and Social Psychology, vol. 39, no. 6, pp. 1161–1178, 1980.

[14] Kohzoh Yoshino and Katsunori Matsuoka. Correlation between mood and heart rate variability indices during daily life. 2011.

[15] Barry Goldstein. Music and the Brain: The Fascinating Ways That Music Affects Your Mood and Mind. 

[16] Ahmed Alqaraawi, Ahmad Alwosheel, and Amr Alsaad. Heart rate variability estimation in photoplethysmography signals using Bayesian learning approach. 2016.

[17] Fred Shaffer and J.P. Ginsbergy. “An Overview of Heart Rate Variability Metrics and Norms”. 2017.

[18] J. Rottenberg, R. D. Ray, and J. J. Gross, “Emotion elicitation using films.” 2007.

[19] Amir Abdi. Keras to TensorFlow. https://github.com/amir-abdi/keras_to_tensorflow accessed February 2019. 